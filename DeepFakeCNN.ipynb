{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:17:34.692544: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-18 20:17:35.572544: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tqdm import tqdm\n",
    "import tensorflow.keras as keras\n",
    "import frame_extractor as extractor\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401/401 [00:46<00:00,  8.64it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "parent = os.path.dirname(os.getcwd())\n",
    "videos = os.listdir(parent + \"/train_sample_videos/\")\n",
    "f = open(parent + \"/train_sample_videos/metadata.json\")\n",
    "valid = json.load(f)\n",
    "for video in tqdm(videos):\n",
    "    if video != \"metadata.json\":\n",
    "        for frame in extractor.run_extraction(parent + \"/train_sample_videos/\" + video):\n",
    "            train_X.append(frame)\n",
    "            break\n",
    "        train_Y.append(1 if valid[video][\"label\"] == \"FAKE\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_orientation(train_X):\n",
    "    h_sum = 0\n",
    "    v_sum = 0\n",
    "    uhoh_sum = 0\n",
    "    for nar in train_X:\n",
    "        if(nar.shape==(1920,1080,3)):\n",
    "            h_sum+=1\n",
    "        elif(nar.shape==(1080,1920,3)):\n",
    "            v_sum+=1\n",
    "        else:\n",
    "            uhoh_sum+=1\n",
    "\n",
    "\n",
    "    print(h_sum)\n",
    "    print(v_sum)\n",
    "    print(uhoh_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_vertical(x):\n",
    "    if x.shape == (1920,1080,3):\n",
    "        return np.rot90(x)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_train_X = list(map(rotate_vertical, train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = rotated_train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore this for now, I don't think we want to filter verticals, \n",
    "#but maybe in the future we'll have to, so this code is nice as a failsafe\n",
    "# def filter_horizontal(x):\n",
    "#     return x.shape==(1080,1920,3)\n",
    "# only_horizontal = list(filter(filter_horizontal, train_X))\n",
    "# check_orientation(only_horizontal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model\n",
    "This cell creates the cnn model to be trained. (Currently a basic CNN example model, not our finished model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_epochs = 10\n",
    "cnn_batch_size = 16\n",
    "train_samples = len(train_X)#TODO: Input number of samples: something like \"len(x_train)\", if x_train is our training array\n",
    "input_shape = (1080,1920,3) #TODO: Set input_shape to the shape of our input\n",
    "num_classes = 2\n",
    "\n",
    "steps_per_epoch = train_samples/cnn_batch_size\n",
    "\n",
    "cnn_model = tensorflow.keras.models.Sequential()\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape)) \n",
    "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "cnn_model.add(Flatten())\n",
    "# cnn_model.add(Dense(32, activation='relu'))\n",
    "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
    "cnn_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 20:24:33.885580: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:1014] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_6/dropout_5/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-11-18 20:24:44.147489: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 759.38MiB (rounded to 796262400)requested by op sequential_6/Cast\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-11-18 20:24:44.147582: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-11-18 20:24:44.147611: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 75, Chunks in use: 74. 18.8KiB allocated for chunks. 18.5KiB in use in bin. 3.2KiB client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147630: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147647: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147665: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 9, Chunks in use: 9. 31.2KiB allocated for chunks. 31.2KiB in use in bin. 29.9KiB client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147682: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 3, Chunks in use: 2. 16.2KiB allocated for chunks. 11.0KiB in use in bin. 6.5KiB client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147697: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147711: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147726: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 1, Chunks in use: 0. 57.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147745: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 4, Chunks in use: 4. 288.0KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147763: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 3, Chunks in use: 2. 416.8KiB allocated for chunks. 280.0KiB in use in bin. 144.0KiB client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147777: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147791: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147805: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147825: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147840: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147854: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147868: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147882: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147896: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147912: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 9, Chunks in use: 8. 2.10GiB allocated for chunks. 1.85GiB in use in bin. 1.66GiB client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147931: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 5, Chunks in use: 4. 11.38GiB allocated for chunks. 10.88GiB in use in bin. 10.88GiB client-requested in use in bin.\n",
      "2023-11-18 20:24:44.147948: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 759.38MiB was 256.00MiB, Chunk State: \n",
      "2023-11-18 20:24:44.147979: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 503.32MiB | Requested Size: 251.66MiB | in_use: 0 | bin_num: 20, prev:   Size: 251.66MiB | Requested Size: 251.66MiB | in_use: 1 | bin_num: -1, next:   Size: 2.32GiB | Requested Size: 2.32GiB | in_use: 1 | bin_num: -1\n",
      "2023-11-18 20:24:44.147992: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 14467596288\n",
      "2023-11-18 20:24:44.148009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000000 of size 256 next 1\n",
      "2023-11-18 20:24:44.148022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000100 of size 1280 next 2\n",
      "2023-11-18 20:24:44.148035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000600 of size 256 next 3\n",
      "2023-11-18 20:24:44.148047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000700 of size 256 next 4\n",
      "2023-11-18 20:24:44.148059: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000800 of size 256 next 6\n",
      "2023-11-18 20:24:44.148072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000900 of size 256 next 7\n",
      "2023-11-18 20:24:44.148084: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000a00 of size 256 next 5\n",
      "2023-11-18 20:24:44.148095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000b00 of size 256 next 8\n",
      "2023-11-18 20:24:44.148107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000c00 of size 256 next 13\n",
      "2023-11-18 20:24:44.148119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000d00 of size 256 next 11\n",
      "2023-11-18 20:24:44.148132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000e00 of size 256 next 12\n",
      "2023-11-18 20:24:44.148143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434000f00 of size 256 next 18\n",
      "2023-11-18 20:24:44.148155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434001000 of size 256 next 16\n",
      "2023-11-18 20:24:44.148167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434001100 of size 256 next 17\n",
      "2023-11-18 20:24:44.148180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434001200 of size 256 next 21\n",
      "2023-11-18 20:24:44.148191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434001300 of size 256 next 22\n",
      "2023-11-18 20:24:44.148208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434001400 of size 4864 next 9\n",
      "2023-11-18 20:24:44.148224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434002700 of size 3584 next 10\n",
      "2023-11-18 20:24:44.148237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434003500 of size 256 next 24\n",
      "2023-11-18 20:24:44.148248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434003600 of size 256 next 25\n",
      "2023-11-18 20:24:44.148260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434003700 of size 256 next 26\n",
      "2023-11-18 20:24:44.148272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434003800 of size 3584 next 27\n",
      "2023-11-18 20:24:44.148285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434004600 of size 256 next 28\n",
      "2023-11-18 20:24:44.148298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434004700 of size 142848 next 15\n",
      "2023-11-18 20:24:44.148310: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434027500 of size 73728 next 14\n",
      "2023-11-18 20:24:44.148324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434039500 of size 256 next 29\n",
      "2023-11-18 20:24:44.148342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2434039600 of size 263886848 next 30\n",
      "2023-11-18 20:24:44.148360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be2e00 of size 256 next 31\n",
      "2023-11-18 20:24:44.148377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be2f00 of size 256 next 32\n",
      "2023-11-18 20:24:44.148395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3000 of size 256 next 33\n",
      "2023-11-18 20:24:44.148413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3100 of size 256 next 34\n",
      "2023-11-18 20:24:44.148430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3200 of size 256 next 35\n",
      "2023-11-18 20:24:44.148448: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3300 of size 256 next 36\n",
      "2023-11-18 20:24:44.148465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3400 of size 256 next 37\n",
      "2023-11-18 20:24:44.148482: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3500 of size 256 next 38\n",
      "2023-11-18 20:24:44.148499: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3600 of size 256 next 39\n",
      "2023-11-18 20:24:44.148515: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3700 of size 256 next 40\n",
      "2023-11-18 20:24:44.148532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3800 of size 256 next 41\n",
      "2023-11-18 20:24:44.148549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3900 of size 256 next 45\n",
      "2023-11-18 20:24:44.148566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3a00 of size 256 next 49\n",
      "2023-11-18 20:24:44.148583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3b00 of size 256 next 44\n",
      "2023-11-18 20:24:44.148600: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3c00 of size 256 next 42\n",
      "2023-11-18 20:24:44.148618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be3d00 of size 3328 next 53\n",
      "2023-11-18 20:24:44.148635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be4a00 of size 256 next 55\n",
      "2023-11-18 20:24:44.148652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be4b00 of size 256 next 56\n",
      "2023-11-18 20:24:44.148669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be4c00 of size 256 next 58\n",
      "2023-11-18 20:24:44.148681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be4d00 of size 256 next 59\n",
      "2023-11-18 20:24:44.148698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be4e00 of size 256 next 60\n",
      "2023-11-18 20:24:44.148714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be4f00 of size 256 next 61\n",
      "2023-11-18 20:24:44.148732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be5000 of size 256 next 62\n",
      "2023-11-18 20:24:44.148748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be5100 of size 256 next 63\n",
      "2023-11-18 20:24:44.148765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be5200 of size 256 next 64\n",
      "2023-11-18 20:24:44.148777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be5300 of size 256 next 67\n",
      "2023-11-18 20:24:44.148796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be5400 of size 256 next 70\n",
      "2023-11-18 20:24:44.148808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be5500 of size 256 next 65\n",
      "2023-11-18 20:24:44.148824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be5600 of size 256 next 43\n",
      "2023-11-18 20:24:44.148837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be5700 of size 3584 next 46\n",
      "2023-11-18 20:24:44.148854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be6500 of size 3584 next 54\n",
      "2023-11-18 20:24:44.148867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443be7300 of size 143872 next 48\n",
      "2023-11-18 20:24:44.148885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c0a500 of size 73728 next 47\n",
      "2023-11-18 20:24:44.148898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1c500 of size 256 next 66\n",
      "2023-11-18 20:24:44.148916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1c600 of size 256 next 73\n",
      "2023-11-18 20:24:44.148928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1c700 of size 256 next 75\n",
      "2023-11-18 20:24:44.148946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1c800 of size 6400 next 69\n",
      "2023-11-18 20:24:44.148965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1e100 of size 3584 next 68\n",
      "2023-11-18 20:24:44.148986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1ef00 of size 256 next 77\n",
      "2023-11-18 20:24:44.148998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1f000 of size 256 next 76\n",
      "2023-11-18 20:24:44.149015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1f100 of size 256 next 78\n",
      "2023-11-18 20:24:44.149027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1f200 of size 256 next 92\n",
      "2023-11-18 20:24:44.149046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1f300 of size 256 next 94\n",
      "2023-11-18 20:24:44.149059: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1f400 of size 256 next 93\n",
      "2023-11-18 20:24:44.149076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1f500 of size 256 next 89\n",
      "2023-11-18 20:24:44.149089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1f600 of size 256 next 87\n",
      "2023-11-18 20:24:44.149106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1f700 of size 256 next 95\n",
      "2023-11-18 20:24:44.149118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1f800 of size 256 next 98\n",
      "2023-11-18 20:24:44.149134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1f900 of size 256 next 100\n",
      "2023-11-18 20:24:44.149147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1fa00 of size 256 next 101\n",
      "2023-11-18 20:24:44.149164: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1fb00 of size 256 next 102\n",
      "2023-11-18 20:24:44.149177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1fc00 of size 256 next 104\n",
      "2023-11-18 20:24:44.149195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1fd00 of size 256 next 79\n",
      "2023-11-18 20:24:44.149208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c1fe00 of size 3584 next 80\n",
      "2023-11-18 20:24:44.149225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f2443c20c00 of size 140032 next 71\n",
      "2023-11-18 20:24:44.149238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c42f00 of size 73728 next 72\n",
      "2023-11-18 20:24:44.149254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c54f00 of size 3584 next 90\n",
      "2023-11-18 20:24:44.149266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c55d00 of size 256 next 88\n",
      "2023-11-18 20:24:44.149284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c55e00 of size 256 next 96\n",
      "2023-11-18 20:24:44.149297: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c55f00 of size 256 next 83\n",
      "2023-11-18 20:24:44.149314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c56000 of size 256 next 86\n",
      "2023-11-18 20:24:44.149326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c56100 of size 256 next 91\n",
      "2023-11-18 20:24:44.149344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f2443c56200 of size 256 next 108\n",
      "2023-11-18 20:24:44.149357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c56300 of size 256 next 109\n",
      "2023-11-18 20:24:44.149374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f2443c56400 of size 5376 next 97\n",
      "2023-11-18 20:24:44.149386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c57900 of size 3584 next 103\n",
      "2023-11-18 20:24:44.149399: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c58700 of size 256 next 106\n",
      "2023-11-18 20:24:44.149411: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c58800 of size 256 next 107\n",
      "2023-11-18 20:24:44.149428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f2443c58900 of size 58880 next 82\n",
      "2023-11-18 20:24:44.149441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c66f00 of size 73728 next 81\n",
      "2023-11-18 20:24:44.149459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2443c78f00 of size 263271936 next 20\n",
      "2023-11-18 20:24:44.149478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f245378c500 of size 263886848 next 19\n",
      "2023-11-18 20:24:44.149491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2463335d00 of size 2488320000 next 23\n",
      "2023-11-18 20:24:44.149509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f24f7841d00 of size 263886848 next 57\n",
      "2023-11-18 20:24:44.149529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f25073eb500 of size 263886848 next 51\n",
      "2023-11-18 20:24:44.149541: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2516f94d00 of size 263886848 next 50\n",
      "2023-11-18 20:24:44.149558: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2526b3e500 of size 2488320000 next 52\n",
      "2023-11-18 20:24:44.149572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f25bb04a500 of size 4222189568 next 74\n",
      "2023-11-18 20:24:44.149589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f26b6ae2500 of size 263886848 next 85\n",
      "2023-11-18 20:24:44.149610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f26c668bd00 of size 263886848 next 84\n",
      "2023-11-18 20:24:44.149622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f26d6235500 of size 527773696 next 99\n",
      "2023-11-18 20:24:44.149639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f26f5988500 of size 2488320000 next 105\n",
      "2023-11-18 20:24:44.149660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f2789e94500 of size 141343488 next 18446744073709551615\n",
      "2023-11-18 20:24:44.149680: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-11-18 20:24:44.149696: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 74 Chunks of size 256 totalling 18.5KiB\n",
      "2023-11-18 20:24:44.149716: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-11-18 20:24:44.149735: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3328 totalling 3.2KiB\n",
      "2023-11-18 20:24:44.149749: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 8 Chunks of size 3584 totalling 28.0KiB\n",
      "2023-11-18 20:24:44.149767: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4864 totalling 4.8KiB\n",
      "2023-11-18 20:24:44.149788: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6400 totalling 6.2KiB\n",
      "2023-11-18 20:24:44.149802: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 73728 totalling 288.0KiB\n",
      "2023-11-18 20:24:44.149821: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 142848 totalling 139.5KiB\n",
      "2023-11-18 20:24:44.149842: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 143872 totalling 140.5KiB\n",
      "2023-11-18 20:24:44.149863: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 141343488 totalling 134.79MiB\n",
      "2023-11-18 20:24:44.149883: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 263271936 totalling 251.08MiB\n",
      "2023-11-18 20:24:44.149903: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 263886848 totalling 1.47GiB\n",
      "2023-11-18 20:24:44.149923: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 2488320000 totalling 6.95GiB\n",
      "2023-11-18 20:24:44.149942: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4222189568 totalling 3.93GiB\n",
      "2023-11-18 20:24:44.149963: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 12.74GiB\n",
      "2023-11-18 20:24:44.149976: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 14467596288 memory_limit_: 14467596288 available bytes: 0 curr_region_allocation_bytes_: 28935192576\n",
      "2023-11-18 20:24:44.150002: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                     14467596288\n",
      "InUse:                     13675731200\n",
      "MaxInUse:                  13940386048\n",
      "NumAllocs:                         234\n",
      "MaxAllocSize:               8468905984\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-11-18 20:24:44.150039: W tensorflow/tsl/framework/bfc_allocator.cc:497] *************************_*****************************************************__*******************\n",
      "2023-11-18 20:24:44.150068: W tensorflow/core/framework/op_kernel.cc:1818] RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "2023-11-18 20:24:44.150117: I tensorflow/core/common_runtime/executor.cc:1209] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "\t [[{{node sequential_6/Cast}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_6/Cast' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_500606/540485387.py\", line 1, in <module>\n      cnn_model.fit(x=np.array(train_X),y=np.array(train_Y),epochs=cnn_epochs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 651, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 748, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential_6/Cast'\nfailed to allocate memory\n\t [[{{node sequential_6/Cast}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2549]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcnn_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_6/Cast' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_500606/540485387.py\", line 1, in <module>\n      cnn_model.fit(x=np.array(train_X),y=np.array(train_Y),epochs=cnn_epochs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 651, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 748, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential_6/Cast'\nfailed to allocate memory\n\t [[{{node sequential_6/Cast}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2549]"
     ]
    }
   ],
   "source": [
    "cnn_model.fit(x=np.array(train_X),y=np.array(train_Y),epochs=cnn_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
