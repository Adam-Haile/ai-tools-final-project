{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project \n",
    "\n",
    "**Title**: Deep Fake Detection\n",
    "\n",
    "**Contributors**: Adam Haile, Alhagie Boye, Rudolph Evonich\n",
    "\n",
    "**Onjective**: To develop a robust CNN model capable of accurately classifying video frames as real or fake.\n",
    "\n",
    "\n",
    "This is a demo of our CNN model that will be use to classify videos as real or fake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 17:05:04.729165: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-03 17:05:04.771074: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-03 17:05:04.771101: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-03 17:05:04.772225: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-03 17:05:04.778336: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.utils import shuffle\n",
    "from video_utils import load_data\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading & Data Preprocessing\n",
    "The following cells handles the loading of video data and associated metadata and data preprocessing.\n",
    "\n",
    "Video files and their corresponding metadata are retrieved from a designated directory (train_sample_videos/) and a JSON file (metadata.json).\n",
    "\n",
    "A custom module named frame_extractor is utilized to extract frame from each video for further processing.\n",
    "\n",
    "The orientation of the frames is checked, and those with vertical orientation are rotated to ensure consistency.\n",
    "\n",
    "Based on the metadata information, binary labels are assigned to each frame: 1 for \"FAKE\" videos and 0 for \"REAL\" videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = os.path.dirname(os.getcwd())\n",
    "videos = glob.glob(parent + \"/train_sample_videos/*.mp4\")[:100]\n",
    "f = open(parent + \"/train_sample_videos/metadata.json\")\n",
    "valid = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/test split\n"
     ]
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = load_data(videos, valid)\n",
    "train_X, train_y = shuffle(train_X, train_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 640, 360, 3)\n",
      "(2400, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(extract_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_frames = np.count_nonzero(np.all(train_Y == np.array([0, 1]), axis=1))\n",
    "# fake_frames = np.count_nonzero(np.all(train_Y == np.array([1, 0]), axis=1))\n",
    "\n",
    "# while true_frames < fake_frames:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation and Training\n",
    "This cell creates the cnn model to be trained. (Currently a basic CNN example model, not our finished model)\n",
    "\n",
    "This serves as a basic example and comprises a convolutional layer, max-pooling, flattening, and two dense layers.\n",
    "\n",
    "The dataset is split into training and validation sets to assess the model's performance during training.\n",
    "\n",
    "The model is trained on the training set for a specified number of epochs and batch size.\n",
    "\n",
    "The training and validation accuracy are visualized over epochs using matplotlib to track the model's learning progress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 10\n",
    "input_shape = (640, 360, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 638, 358, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 319, 179, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 317, 177, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 158, 88, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 889856)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                14237712  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14257138 (54.39 MB)\n",
      "Trainable params: 14257138 (54.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 17:05:51.933805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13811 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:60:00.0, compute capability: 7.5\n",
      "2023-12-03 17:05:51.935595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13811 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:61:00.0, compute capability: 7.5\n",
      "2023-12-03 17:05:51.937151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 13811 MB memory:  -> device: 2, name: Tesla T4, pci bus id: 0000:da:00.0, compute capability: 7.5\n",
      "2023-12-03 17:05:51.938820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 13811 MB memory:  -> device: 3, name: Tesla T4, pci bus id: 0000:db:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 17:06:01.784393: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8901\n",
      "2023-12-03 17:06:03.183448: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f88a7812410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-03 17:06:03.183483: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-12-03 17:06:03.183488: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "2023-12-03 17:06:03.183493: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5\n",
      "2023-12-03 17:06:03.183497: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5\n",
      "2023-12-03 17:06:03.188322: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1701641163.301534  871222 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 30s 172ms/step - loss: 0.7355 - accuracy: 0.8033 - val_loss: 0.3753 - val_accuracy: 0.7900\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 0.2714 - accuracy: 0.8725 - val_loss: 0.2562 - val_accuracy: 0.9217\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.2222 - accuracy: 0.9212 - val_loss: 0.2857 - val_accuracy: 0.9100\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.1856 - accuracy: 0.9438 - val_loss: 0.2301 - val_accuracy: 0.9333\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.1695 - accuracy: 0.9450 - val_loss: 0.1836 - val_accuracy: 0.9400\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.1553 - accuracy: 0.9500 - val_loss: 0.1546 - val_accuracy: 0.9450\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 13s 90ms/step - loss: 0.1392 - accuracy: 0.9538 - val_loss: 0.2017 - val_accuracy: 0.9100\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.1414 - accuracy: 0.9458 - val_loss: 0.1353 - val_accuracy: 0.9450\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 14s 92ms/step - loss: 0.1191 - accuracy: 0.9608 - val_loss: 0.1305 - val_accuracy: 0.9533\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 14s 91ms/step - loss: 0.1096 - accuracy: 0.9638 - val_loss